{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cant do\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "sys.path.append('../')\n",
    "sys.path.append('old_configs/')\n",
    "warnings.filterwarnings('ignore')\n",
    "try:\n",
    "    sys.modules.pop('src.modeling.autocompletion')\n",
    "except:\n",
    "    print('cant do')\n",
    "\n",
    "import torch\n",
    "import tokenizers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from pygments.token import Token\n",
    "from catalyst.utils import load_checkpoint, unpack_checkpoint\n",
    "\n",
    "from src.preprocessing.preprocessing import LexerBasedPreprocessor\n",
    "from src.preprocessing.tokenization import BertWordPieceTokenizerWrapper, SentencepieceTokenizerWrapper\n",
    "from src.generation.generation_utils import TokenScoresPostprocessor, NextTokenChooser\n",
    "from src.generation.autocompletion import AutocompletionModel\n",
    "from src.generation.postprocessing import get_first_word\n",
    "from src.preprocessing.tokenization import clever_join\n",
    "from src.generation.prefix_utils import PrefixMatcher\n",
    "from src.utils.metrics import reciprocal_rank, relevant_in_k\n",
    "\n",
    "from run_gpt_ddp_training import GPT2ConfigInitializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocesser\n",
    "DATA_DIR = '/mnt/data/popov/rcompletion/evaluation_data/'\n",
    "with open('/home/popov/data/rcompletion_files/december2020_best_model/top_tokens_bigdata_021020.json', 'r') as f:\n",
    "    top_tokens = json.load(f)\n",
    "top_tokens = set(top_tokens)\n",
    "preprocesser = LexerBasedPreprocessor(protected_names=top_tokens)\n",
    "lexer = preprocesser.lexer\n",
    "# tokenizer\n",
    "tokenizer = SentencepieceTokenizerWrapper(f'/mnt/data/porkhun/tokenizer/spm_cased_bpe_16.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_config import Config as gpt_config\n",
    "\n",
    "initializer = GPT2ConfigInitializer(gpt_config)\n",
    "model = initializer.init_model()\n",
    "checkpoint = load_checkpoint('/home/porkhun/model_training/practice/const_shift/shift25/best.pth')\n",
    "unpack_checkpoint(checkpoint=checkpoint, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.student_model\n",
    "model = model.eval().to(f'cuda:{CUDA}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(directory):\n",
    "    dict_for_df = defaultdict(list)\n",
    "    with open(directory, 'r') as f:\n",
    "        for line in f:\n",
    "            d = json.loads(line)\n",
    "            for key in d:\n",
    "                dict_for_df[key].append(d[key])\n",
    "    return pd.DataFrame(dict_for_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>before_cursor</th>\n",
       "      <th>after_cursor</th>\n",
       "      <th>after_cursor_token</th>\n",
       "      <th>right_context</th>\n",
       "      <th>group</th>\n",
       "      <th>prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://api.github.com/repos/CenterForStatisti...</td>\n",
       "      <td>########################\\n#                   ...</td>\n",
       "      <td>otlist</td>\n",
       "      <td>plotlist</td>\n",
       "      <td>=plotlist,labels=LETTERS[1:4])\\ndev.off()</td>\n",
       "      <td>f_key_argument</td>\n",
       "      <td>prefix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://api.github.com/repos/VUW-FAIR/tic-pers...</td>\n",
       "      <td>setwd(\"/Users/mlr/OneDrive - Victoria Universi...</td>\n",
       "      <td>thod</td>\n",
       "      <td>method</td>\n",
       "      <td>= \"euclid\")\\nbarplot(unlist(allDistances))\\n\\...</td>\n",
       "      <td>f_key_argument</td>\n",
       "      <td>prefix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://api.github.com/repos/jayhesselberth/gg...</td>\n",
       "      <td>context(\"ggsave\")\\n\\ntest_that(\"ggsave creates...</td>\n",
       "      <td>cale</td>\n",
       "      <td>scale</td>\n",
       "      <td>= 2), c(10, 10))\\n})\\n\\n\\n# plot_dev --------...</td>\n",
       "      <td>f_key_argument</td>\n",
       "      <td>prefix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://api.github.com/repos/gtesei/fast-furio...</td>\n",
       "      <td>require(xgboost)\\nrequire(methods)\\nlibrary(da...</td>\n",
       "      <td>op</td>\n",
       "      <td>drop</td>\n",
       "      <td>= F]) \\n    test_set = cbind(test_set , data[...</td>\n",
       "      <td>f_key_argument</td>\n",
       "      <td>prefix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://api.github.com/repos/HadiEO/tropical_r...</td>\n",
       "      <td>require(ggplot2)\\nrequire(tidyverse)\\nrequire(...</td>\n",
       "      <td>ir</td>\n",
       "      <td>nir</td>\n",
       "      <td>=seq(0,100,20), swir1=seq(0,100,20), swir2=seq...</td>\n",
       "      <td>f_key_argument</td>\n",
       "      <td>prefix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://api.github.com/repos/CenterForStatisti...   \n",
       "1  https://api.github.com/repos/VUW-FAIR/tic-pers...   \n",
       "2  https://api.github.com/repos/jayhesselberth/gg...   \n",
       "3  https://api.github.com/repos/gtesei/fast-furio...   \n",
       "4  https://api.github.com/repos/HadiEO/tropical_r...   \n",
       "\n",
       "                                       before_cursor after_cursor  \\\n",
       "0  ########################\\n#                   ...       otlist   \n",
       "1  setwd(\"/Users/mlr/OneDrive - Victoria Universi...         thod   \n",
       "2  context(\"ggsave\")\\n\\ntest_that(\"ggsave creates...         cale   \n",
       "3  require(xgboost)\\nrequire(methods)\\nlibrary(da...           op   \n",
       "4  require(ggplot2)\\nrequire(tidyverse)\\nrequire(...           ir   \n",
       "\n",
       "  after_cursor_token                                      right_context  \\\n",
       "0           plotlist          =plotlist,labels=LETTERS[1:4])\\ndev.off()   \n",
       "1             method   = \"euclid\")\\nbarplot(unlist(allDistances))\\n\\...   \n",
       "2              scale   = 2), c(10, 10))\\n})\\n\\n\\n# plot_dev --------...   \n",
       "3               drop   = F]) \\n    test_set = cbind(test_set , data[...   \n",
       "4                nir  =seq(0,100,20), swir1=seq(0,100,20), swir2=seq...   \n",
       "\n",
       "            group  prefix  \n",
       "0  f_key_argument  prefix  \n",
       "1  f_key_argument  prefix  \n",
       "2  f_key_argument  prefix  \n",
       "3  f_key_argument  prefix  \n",
       "4  f_key_argument  prefix  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if hasattr(model, 'double_context'):\n",
    "    df = create_df(DATA_DIR+'extracted_events_with_right_context.json')\n",
    "else:\n",
    "    df = create_df(DATA_DIR+'extracted_events.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для измерения зависимости от итерации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8fd6d28cbb4c5a8c546fe4347e5299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "all_real_outputs = dict()\n",
    "all_model_outputs = dict()\n",
    "\n",
    "lines_to_keep = 100\n",
    "# for lines_to_keep in [None, 85, 70, 80, 100, 140]:\n",
    "autocompletion_model = AutocompletionModel(\n",
    "        preprocessor=preprocesser,\n",
    "        tokenizer=tokenizer,\n",
    "        model=model,\n",
    "        score_postprocesser=TokenScoresPostprocessor(temperature=1.5, penalty_theta=0.5),\n",
    "        next_token_chooser=NextTokenChooser(do_sample=False),\n",
    "        max_tokens_amount=5,\n",
    "        num_beams=5,\n",
    "        max_num_sequence_return=20,\n",
    "        input_lines_to_keep=lines_to_keep,\n",
    "    )\n",
    "    \n",
    "model_outputs = []\n",
    "real_outputs = []\n",
    "bad_indexes = []\n",
    "for i, elem in tqdm(df.iterrows()):\n",
    "    if autocompletion_model.double_context:\n",
    "        test_sample = (elem['before_cursor'], elem['right_context'])\n",
    "        \n",
    "    else:\n",
    "        test_sample = elem['before_cursor']\n",
    "    try:\n",
    "        one_model_outputs = autocompletion_model.autocomplete_input(\n",
    "            test_sample,\n",
    "            drop_last_word='always' if elem['prefix'] == 'prefix' else 'never',\n",
    "        )\n",
    "        one_real_output = elem['after_cursor_token']\n",
    "        model_outputs.append(one_model_outputs)\n",
    "        real_outputs.append(one_real_output)\n",
    "    except Exception:\n",
    "#         raise\n",
    "        bad_indexes.append(i)\n",
    "#     if i > 10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all brackets from left context\n",
    "real_o = real_outputs\n",
    "model_o = model_outputs\n",
    "relevances = [\n",
    "    [int(x == one_r_o) for x in one_model_o]\n",
    "    for one_r_o, one_model_o in zip(real_o, model_o)\n",
    "]\n",
    "key_metrics = [\n",
    "    [relevant_in_k(one_r, k=k) for k in range(1, 6)] + [reciprocal_rank(one_r)]\n",
    "    if one_r else [0] * 6\n",
    "    for one_r in relevances\n",
    "]\n",
    "key_metrics = np.array(key_metrics).mean(axis=0)\n",
    "key_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BiGPT 25 shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([key_metrics], columns=['Top 1', 'Top 2', 'Top 3', 'Top 4', 'Top 5', 'MRR']).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bad_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
