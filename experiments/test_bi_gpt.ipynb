{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cant do\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "sys.path.append('../')\n",
    "sys.path.append('old_configs/')\n",
    "warnings.filterwarnings('ignore')\n",
    "try:\n",
    "    sys.modules.pop('src.modeling.autocompletion')\n",
    "except:\n",
    "    print('cant do')\n",
    "\n",
    "import torch\n",
    "import tokenizers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from pygments.token import Token\n",
    "from catalyst.utils import load_checkpoint, unpack_checkpoint\n",
    "\n",
    "from src.preprocessing.preprocessing import LexerBasedPreprocessor\n",
    "from src.preprocessing.tokenization import BertWordPieceTokenizerWrapper, SentencepieceTokenizerWrapper\n",
    "from src.generation.generation_utils import TokenScoresPostprocessor, NextTokenChooser\n",
    "from src.generation.autocompletion import AutocompletionModel\n",
    "from src.generation.postprocessing import get_first_word\n",
    "from src.preprocessing.tokenization import clever_join\n",
    "from src.generation.prefix_utils import PrefixMatcher\n",
    "from src.utils.metrics import reciprocal_rank, relevant_in_k\n",
    "\n",
    "from run_gpt_ddp_training import GPT2ConfigInitializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocesser\n",
    "DATA_DIR = '/mnt/data/popov/rcompletion/evaluation_data/'\n",
    "with open('/home/popov/data/rcompletion_files/december2020_best_model/top_tokens_bigdata_021020.json', 'r') as f:\n",
    "    top_tokens = json.load(f)\n",
    "top_tokens = set(top_tokens)\n",
    "preprocesser = LexerBasedPreprocessor(protected_names=top_tokens)\n",
    "lexer = preprocesser.lexer\n",
    "\n",
    "preprocesser = LexerBasedPreprocessor()\n",
    "lexer = preprocesser.lexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "\n",
    "base_path = '/mnt/disk/shared/popov/data/rcompletion/bigdata_ver1/'\n",
    "tokenizer = SentencepieceTokenizerWrapper(f'/mnt/data/porkhun/tokenizer/spm_cased_bpe_16.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score postprocesser\n",
    "score_postprocesser = TokenScoresPostprocessor(temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_config import Config as gpt_config\n",
    "\n",
    "initializer = GPT2ConfigInitializer(gpt_config)\n",
    "model = initializer.init_model()\n",
    "checkpoint = load_checkpoint('/home/porkhun/model_training/practice/bi_gpt/30_epoch/best.pth')\n",
    "unpack_checkpoint(checkpoint=checkpoint, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiGPTModel(\n",
       "  (gpt_left_to_right): GPT2Model(\n",
       "    (wte): Embedding(16000, 128)\n",
       "    (wpe): Embedding(512, 128)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (gpt_right_to_left): GPT2Model(\n",
       "    (wte): Embedding(16000, 128)\n",
       "    (wpe): Embedding(512, 128)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=256, out_features=16000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.student_model\n",
    "model = model.eval()\n",
    "\n",
    "CUDA_DEVICE = 'cuda:0'\n",
    "model = model.to(CUDA_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(directory):\n",
    "    dict_for_df = defaultdict(list)\n",
    "    with open(directory, 'r') as f:\n",
    "        for line in f:\n",
    "            d = json.loads(line)\n",
    "            for key in d:\n",
    "                dict_for_df[key].append(d[key])\n",
    "    return pd.DataFrame(dict_for_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>before_cursor</th>\n",
       "      <th>after_cursor</th>\n",
       "      <th>after_cursor_token</th>\n",
       "      <th>right_context</th>\n",
       "      <th>group</th>\n",
       "      <th>prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://api.github.com/repos/CenterForStatisti...</td>\n",
       "      <td>########################\\n#                   ...</td>\n",
       "      <td>otlist</td>\n",
       "      <td>plotlist</td>\n",
       "      <td>=plotlist,labels=LETTERS[1:4])\\ndev.off()</td>\n",
       "      <td>f_key_argument</td>\n",
       "      <td>prefix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://api.github.com/repos/VUW-FAIR/tic-pers...</td>\n",
       "      <td>setwd(\"/Users/mlr/OneDrive - Victoria Universi...</td>\n",
       "      <td>thod</td>\n",
       "      <td>method</td>\n",
       "      <td>= \"euclid\")\\nbarplot(unlist(allDistances))\\n\\...</td>\n",
       "      <td>f_key_argument</td>\n",
       "      <td>prefix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://api.github.com/repos/jayhesselberth/gg...</td>\n",
       "      <td>context(\"ggsave\")\\n\\ntest_that(\"ggsave creates...</td>\n",
       "      <td>cale</td>\n",
       "      <td>scale</td>\n",
       "      <td>= 2), c(10, 10))\\n})\\n\\n\\n# plot_dev --------...</td>\n",
       "      <td>f_key_argument</td>\n",
       "      <td>prefix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://api.github.com/repos/gtesei/fast-furio...</td>\n",
       "      <td>require(xgboost)\\nrequire(methods)\\nlibrary(da...</td>\n",
       "      <td>op</td>\n",
       "      <td>drop</td>\n",
       "      <td>= F]) \\n    test_set = cbind(test_set , data[...</td>\n",
       "      <td>f_key_argument</td>\n",
       "      <td>prefix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://api.github.com/repos/HadiEO/tropical_r...</td>\n",
       "      <td>require(ggplot2)\\nrequire(tidyverse)\\nrequire(...</td>\n",
       "      <td>ir</td>\n",
       "      <td>nir</td>\n",
       "      <td>=seq(0,100,20), swir1=seq(0,100,20), swir2=seq...</td>\n",
       "      <td>f_key_argument</td>\n",
       "      <td>prefix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://api.github.com/repos/CenterForStatisti...   \n",
       "1  https://api.github.com/repos/VUW-FAIR/tic-pers...   \n",
       "2  https://api.github.com/repos/jayhesselberth/gg...   \n",
       "3  https://api.github.com/repos/gtesei/fast-furio...   \n",
       "4  https://api.github.com/repos/HadiEO/tropical_r...   \n",
       "\n",
       "                                       before_cursor after_cursor  \\\n",
       "0  ########################\\n#                   ...       otlist   \n",
       "1  setwd(\"/Users/mlr/OneDrive - Victoria Universi...         thod   \n",
       "2  context(\"ggsave\")\\n\\ntest_that(\"ggsave creates...         cale   \n",
       "3  require(xgboost)\\nrequire(methods)\\nlibrary(da...           op   \n",
       "4  require(ggplot2)\\nrequire(tidyverse)\\nrequire(...           ir   \n",
       "\n",
       "  after_cursor_token                                      right_context  \\\n",
       "0           plotlist          =plotlist,labels=LETTERS[1:4])\\ndev.off()   \n",
       "1             method   = \"euclid\")\\nbarplot(unlist(allDistances))\\n\\...   \n",
       "2              scale   = 2), c(10, 10))\\n})\\n\\n\\n# plot_dev --------...   \n",
       "3               drop   = F]) \\n    test_set = cbind(test_set , data[...   \n",
       "4                nir  =seq(0,100,20), swir1=seq(0,100,20), swir2=seq...   \n",
       "\n",
       "            group  prefix  \n",
       "0  f_key_argument  prefix  \n",
       "1  f_key_argument  prefix  \n",
       "2  f_key_argument  prefix  \n",
       "3  f_key_argument  prefix  \n",
       "4  f_key_argument  prefix  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if hasattr(model, 'double_context'):\n",
    "    df = create_df(DATA_DIR+'extracted_events_with_right_context.json')\n",
    "else:\n",
    "    df = create_df(DATA_DIR+'extracted_events.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'weightsInc'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = df.iloc[10]['after_cursor_token']\n",
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocompletion_model = AutocompletionModel(\n",
    "    preprocessor=preprocesser,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    score_postprocesser=TokenScoresPostprocessor(temperature=1.5, penalty_theta=0.5),\n",
    "    next_token_chooser=NextTokenChooser(do_sample=False),\n",
    "    max_tokens_amount=5,\n",
    "    num_beams=5,\n",
    "    max_num_sequence_return=20,\n",
    "    input_lines_to_keep=85,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для измерения зависимости от итерации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexxerrrr = LexerBasedPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5509075ff9f84b4fa9e7ad60b1a59c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁ )\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Token doesn't satisfy prefix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/new_rcompletion/code-completion-right-context/src/generation/autocompletion.py\u001b[0m in \u001b[0;36mautocomplete_input_bi_gpt\u001b[0;34m(self, input_text, return_probs, drop_last_word)\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0msorted_words_and_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m             output_word_to_prob = self._generate_next_token_ids(\n\u001b[0m\u001b[1;32m    739\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m                 \u001b[0mbad_word_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbad_word_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/new_rcompletion/code-completion-right-context/src/generation/autocompletion.py\u001b[0m in \u001b[0;36m_generate_next_token_ids\u001b[0;34m(self, input_ids, bad_word_ids, old_name_to_new, known_prefix)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;31m# update input ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             model_state, is_end = self._update_model_output_state_after_one_step(\n\u001b[0m\u001b[1;32m    478\u001b[0m                 \u001b[0mmodel_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0mnext_token_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext_token_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/new_rcompletion/code-completion-right-context/src/generation/autocompletion.py\u001b[0m in \u001b[0;36m_update_model_output_state_after_one_step\u001b[0;34m(self, model_state, next_token_info, initial_length, old_name_to_new)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mneed_to_keep_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 one_new_prefix = self.prefix_matcher.get_prefix_for_new_token(\n\u001b[0m\u001b[1;32m    350\u001b[0m                     \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmp_new_prefixes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0mnew_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_sequence_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/new_rcompletion/code-completion-right-context/src/generation/prefix_utils.py\u001b[0m in \u001b[0;36mget_prefix_for_new_token\u001b[0;34m(self, prefix, new_token_id, old_to_new_variables)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnew_token\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_token\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Token doesn't satisfy prefix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Token doesn't satisfy prefix"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_real_outputs = dict()\n",
    "all_model_outputs = dict()\n",
    "\n",
    "lines_to_keep = 100\n",
    "# for lines_to_keep in [None, 85, 70, 80, 100, 140]:\n",
    "autocompletion_model = AutocompletionModel(\n",
    "        preprocessor=preprocesser,\n",
    "        tokenizer=tokenizer,\n",
    "        model=model,\n",
    "        score_postprocesser=TokenScoresPostprocessor(temperature=1.5, penalty_theta=0.5),\n",
    "        next_token_chooser=NextTokenChooser(do_sample=False),\n",
    "        max_tokens_amount=5,\n",
    "        num_beams=5,\n",
    "        max_num_sequence_return=20,\n",
    "        input_lines_to_keep=lines_to_keep,\n",
    "    )\n",
    "    \n",
    "model_outputs = []\n",
    "real_outputs = []\n",
    "bad_indexes = []\n",
    "for i, elem in tqdm(df.iterrows()):\n",
    "    if autocompletion_model.double_context:\n",
    "        test_sample = (elem['before_cursor'], elem['right_context'])\n",
    "        \n",
    "    else:\n",
    "        test_sample = elem['before_cursor']\n",
    "    try:\n",
    "        one_model_outputs = autocompletion_model.autocomplete_input(\n",
    "            test_sample,\n",
    "            drop_last_word='always' if elem['prefix'] == 'prefix' else 'never',\n",
    "        )\n",
    "    except:\n",
    "        raise\n",
    "        bad_indexes.append(i)\n",
    "    if i > 10:\n",
    "        break\n",
    "    one_real_output = elem['after_cursor_token']\n",
    "    model_outputs.append(one_model_outputs)\n",
    "    real_outputs.append(one_real_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bad_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 7, 10, 11]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('   \\n )]F =', \"y_id' , dr\")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['right_context'].iat[3][10:0:-1], df['before_cursor'].iat[3][-10:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([], 'plotlist'),\n",
       " ([], 'method'),\n",
       " ([], 'scale'),\n",
       " (['drop', '=', 'gnario', 'exact', 'gngnario'], 'drop'),\n",
       " ([], 'nir'),\n",
       " ([], 'collapse'),\n",
       " ([], 'decreasing'),\n",
       " ([], 'license'),\n",
       " ([], 'dependencies'),\n",
       " ([], 'tol'),\n",
       " ([], 'weightsInc')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(model_outputs, real_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05373704, 0.0851992 , 0.10527836, 0.1165747 , 0.12558865,\n",
       "       0.08251272])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_o = real_outputs\n",
    "model_o = model_outputs\n",
    "relevances = [\n",
    "    [int(x == one_r_o) for x in one_model_o]\n",
    "    for one_r_o, one_model_o in zip(real_o, model_o)\n",
    "]\n",
    "key_metrics = [\n",
    "    [relevant_in_k(one_r, k=k) for k in range(1, 6)] + [reciprocal_rank(one_r)]\n",
    "    if one_r else [0] * 6\n",
    "    for one_r in relevances\n",
    "]\n",
    "key_metrics = np.array(key_metrics).mean(axis=0)\n",
    "key_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00043336, 0.00057782, 0.00060671, 0.00060671, 0.00066449,\n",
       "       0.00053792])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_o = real_outputs\n",
    "model_o = model_outputs\n",
    "relevances = [\n",
    "    [int(x == one_r_o) for x in one_model_o]\n",
    "    for one_r_o, one_model_o in zip(real_o, model_o)\n",
    "]\n",
    "key_metrics = [\n",
    "    [relevant_in_k(one_r, k=k) for k in range(1, 6)] + [reciprocal_rank(one_r)]\n",
    "    if one_r else [0] * 6\n",
    "    for one_r in relevances\n",
    "]\n",
    "key_metrics = np.array(key_metrics).mean(axis=0)\n",
    "key_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_metrics = dict()\n",
    "\n",
    "for one_key in sorted(all_real_outputs.keys()):\n",
    "    real_o = all_real_outputs[one_key]\n",
    "    model_o = all_model_outputs[one_key]\n",
    "    \n",
    "    relevances = [\n",
    "        [int(x == one_r_o) for x in one_model_o]\n",
    "        for one_r_o, one_model_o in zip(real_o, model_o)\n",
    "    ]\n",
    "    \n",
    "    key_metrics = [\n",
    "        [relevant_in_k(one_r, k=k) for k in range(1, 6)] + [reciprocal_rank(one_r)]\n",
    "        if one_r else [0] * 6\n",
    "        for one_r in relevances\n",
    "    ]\n",
    "    \n",
    "    key_metrics = np.array(key_metrics).mean(axis=0)\n",
    "    key_to_metrics[one_key] = key_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_metric_list = sorted(key_to_metrics.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_metric_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-346d8d430dc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_metric_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_metric_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_metric_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey_metric_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_metric_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2, 3)\n",
    "\n",
    "fig.set_figwidth(17)\n",
    "fig.set_figheight(7)\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.plot([x[0] for x in key_metric_list[:-1]], [x[1][-1] for x in key_metric_list[:-1]], '-o')\n",
    "plt.plot([x[0] for x in key_metric_list[:-1]], [key_metric_list[-1][1][-1]] * (len(key_metric_list) - 1), '--')\n",
    "\n",
    "\n",
    "plt.legend(['distilled model'], fontsize=14)\n",
    "plt.ylabel('MPR')\n",
    "plt.xlabel('keeped line amount')\n",
    "plt.xticks([x[0] for x in key_metric_list[:-1]])\n",
    "    \n",
    "\n",
    "for top_i in range(0, 5):\n",
    "    plt.subplot(2, 3, top_i + 2)    \n",
    "    plt.plot([x[0] for x in key_metric_list[:-1]], [x[1][top_i] for x in key_metric_list[:-1]], '-o')\n",
    "    plt.plot([x[0] for x in key_metric_list[:-1]], [key_metric_list[-1][1][top_i]] * (len(key_metric_list) - 1), '--')\n",
    "\n",
    "    plt.xlabel('keeped line amount')\n",
    "    plt.xticks([x[0] for x in key_metric_list[:-1]])\n",
    "    plt.ylabel(f'right in top_{top_i + 1}')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[   13,   180,   109,   868, 15920,     4,   148,  2191,    59,     5,\n",
    "            13,   180,   109,   599,    57, 15930,   417,   180, 15928, 15930,\n",
    "           417,  2191, 15928, 15930,   417,  1066,    59,     5,   728,     5,\n",
    "            19,  1322, 15917,  1440,    92,     8,  1897,  3975, 15920,   308,\n",
    "           553,     5,    19,     8,  1987,  3975, 15920,   308,   553,     5,\n",
    "            19,   310, 15920, 15924,    15, 15940,  4760,     5,   835,     8,\n",
    "          2015,  1667, 15920,   465,  9831, 15920,     4,  1759, 15924,  6692,\n",
    "          2496, 15917,  2418, 15920,     4,  1759, 15924,   268, 12437,     8,\n",
    "          1277, 15924,  2717,     4,  3235,     5,    62,     8,  1412, 15924,\n",
    "          9497,     5,  1156,     4,  3235,     5,    62,   106,  3013,    57,\n",
    "           507,    59,     5,   728,     5,    13,  1104,    59,     5,   728,\n",
    "             5,    19,   382, 15920, 10418, 15928, 15930,   501,   382, 15920,\n",
    "            73, 15924, 15928, 15930,   501,   382, 15920,   965, 15928, 15930,\n",
    "           501,   310, 15920, 15924,    15, 15940,  4760,     5,   835,     8,\n",
    "          2163, 15972,  2796, 15920,   695,    48,     5,    69,     5,    69,\n",
    "             5,   728,     5,   107,  1367, 15928,     4,  1277, 15924,   220,\n",
    "           870, 15928,     4,  1412, 15924,   268, 10945, 15920,     4,   362,\n",
    "             4,  1759, 15924,  6692,  2496, 15917,  2418, 15920,     4,  1759,\n",
    "         15924,   268,   220,  1140,   102,  1175,   102,   925, 15928,   402,\n",
    "            57, 15924, 15919,  1044,  2899,  1066, 15917,    80,    59,     5,\n",
    "            13,  1066, 15917,   571,    59,     5,    13,  1066, 15917,   925,\n",
    "            59,     5,    13,  1066, 15917,   323,    59,     5,    13,  1066,\n",
    "            59,     5,    19,  2725, 15920,  2055,    59,     5,    13,   166,\n",
    "           102,   205,    59,     5,    13,  1066,    59,     5,    19,   191,\n",
    "         15920, 15924, 15949,    15, 15949, 15930, 14893, 15931,   166, 15920,\n",
    "          2055,    59,     5,    13,   166,   102,   205,    59,     5,    13,\n",
    "          1066,    59,     5,  4515,  3864, 15920,     4,  1759, 15924,  6692,\n",
    "          2496, 15917,  2418, 15920,     4,  1759, 15924,   268,   220,  5240,\n",
    "         15928,   814, 15920, 15935, 15921, 15972,  2796, 15920, 15935, 15919,\n",
    "          1367, 15928,     4,  1277, 15924,   220,   870, 15928,     4,  1412,\n",
    "         15924,  1434,   106,  1322, 15917,  1440,    92,     8,  2310,   327,\n",
    "            92,   310, 15920, 15924,    15, 15940,  4760,     5,   835,     8,\n",
    "          2852,     4,  1759, 15924,  6692,  2496, 15917,  2418, 15920,     4,\n",
    "          1759, 15924,  7314,     8,  3036,  2194, 15920,     4,   682, 15930,\n",
    "           501,     8,  3115, 15972,  2796, 15920, 15930,   417,  1367, 15928,\n",
    "             4,  1277, 15924,   220,   870, 15928,     4,  1412, 15924,   268,\n",
    "             8,  3262,   939, 15920,     4,   993, 15984,   939, 15920,     4,\n",
    "          1054,     8,  3447,     4,  4172,     5,  4056,     4,   178, 15982,\n",
    "             4,  4405,     5,    62,     8,  3572,    45, 15917,   211, 15920,\n",
    "             4,   920,     8,  7682, 15924,  6846,   554, 15920,    45, 15928,\n",
    "             4,   887,   212, 15920,   643, 15928,     4,   123,   848,   485,\n",
    "         15938,  4537, 15920,  5240, 15928, 15972,  2796, 15919, 15934,  1574,\n",
    "         15928,   327, 15920,  1367, 15928,     4,  1277, 15924,   220,   870,\n",
    "         15928,     4,  1412, 15924,  1642,   274,    59,     5,   728,     5,\n",
    "           979,  1140,  1155,  1175,  1155,   219, 15938,   778,   923,   971,\n",
    "         15938,  2250, 15920,  2964, 15928,     4,   808,   820, 15928,     4,\n",
    "          1147, 15954,   219, 15920,   571, 15917,   183, 15928,   734, 15938,\n",
    "           166, 15920,   274,    59,     5,   107,   571, 15917,   166, 15928,\n",
    "           734, 15938,   166, 15920,   274,    59,     5,   116,   106,  3013,\n",
    "            57,   507,    59,     5,   728,     5,    13,  1104,    59,     5,\n",
    "           728,     5,    19,   174, 15938,   498, 15920]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([1, 0, 0, 1, 1, 0, 0, 1, 0, 1]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a4c7f1fad2ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "x[y]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
