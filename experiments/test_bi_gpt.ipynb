{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cant do\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "from enum import Enum\n",
    "from collections import defaultdict\n",
    "\n",
    "sys.path.append('../')\n",
    "sys.path.append('old_configs/')\n",
    "warnings.filterwarnings('ignore')\n",
    "try:\n",
    "    sys.modules.pop('src.modeling.autocompletion')\n",
    "except:\n",
    "    print('cant do')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from catalyst.utils import load_checkpoint, unpack_checkpoint\n",
    "\n",
    "from src.preprocessing.preprocessing import LexerBasedPreprocessor\n",
    "from src.preprocessing.tokenization import SentencepieceTokenizerWrapper\n",
    "from src.generation.generation_utils import (\n",
    "    BiTokenScoresPostprocessor,\n",
    "    TokenScoresPostprocessor,\n",
    "    NextTokenChooser\n",
    ")\n",
    "from src.generation.autocompletion import AutocompletionModel, BiAutocompletionModel\n",
    "from src.utils.metrics import reciprocal_rank, relevant_in_k\n",
    "\n",
    "from src.modeling.gpt2_config_initializer import GPT2ConfigInitializer\n",
    "from src.modeling.bi_gpt2_config_initializer import BiGPT2ConfigInitializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "CUDA_DEVICE = 'cuda:4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocesser\n",
    "DATA_DIR = '/mnt/data/popov/rcompletion/evaluation_data/'\n",
    "with open('/home/popov/data/rcompletion_files/december2020_best_model/top_tokens_bigdata_021020.json', 'r') as f:\n",
    "    top_tokens = json.load(f)\n",
    "top_tokens = set(top_tokens)\n",
    "preprocesser = LexerBasedPreprocessor(protected_names=top_tokens)\n",
    "lexer = preprocesser.lexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "base_path = '/mnt/disk/shared/popov/data/rcompletion/bigdata_ver1/'\n",
    "tokenizer = SentencepieceTokenizerWrapper(f'/mnt/data/porkhun/tokenizer/spm_cased_bpe_16.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score postprocesser\n",
    "score_postprocesser = TokenScoresPostprocessor(temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Enum):\n",
    "    GPT = 1\n",
    "    BiGPT = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_config import Config as gpt_config\n",
    "if gpt_config.TYPE_MODEL == 'GPT2':\n",
    "    initializer = GPT2ConfigInitializer(gpt_config)\n",
    "    model = initializer.init_model()\n",
    "    model_type = Model.GPT\n",
    "elif gpt_config.TYPE_MODEL == 'BiGPT2':\n",
    "    initializer = BiGPT2ConfigInitializer(gpt_config)\n",
    "    model = initializer.init_model()\n",
    "    model_type = Model.BiGPT\n",
    "else:\n",
    "    raise ValueError('Strange model type')\n",
    "if gpt_config.CHECKPOINT_PATH:\n",
    "    checkpoint = load_checkpoint(gpt_config.CHECKPOINT_PATH)\n",
    "    unpack_checkpoint(checkpoint=checkpoint, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.student_model\n",
    "model = model.eval()\n",
    "model = model.to(CUDA_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(directory):\n",
    "    dict_for_df = defaultdict(list)\n",
    "    with open(directory, 'r') as f:\n",
    "        for line in f:\n",
    "            d = json.loads(line)\n",
    "            for key in d:\n",
    "                dict_for_df[key].append(d[key])\n",
    "    return pd.DataFrame(dict_for_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>before_cursor</th>\n",
       "      <th>after_cursor</th>\n",
       "      <th>after_cursor_token</th>\n",
       "      <th>group</th>\n",
       "      <th>prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://api.github.com/repos/CenterForStatisti...</td>\n",
       "      <td>########################\\n#                   ...</td>\n",
       "      <td>otlist</td>\n",
       "      <td>plotlist</td>\n",
       "      <td>f_key_argument</td>\n",
       "      <td>prefix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://api.github.com/repos/VUW-FAIR/tic-pers...</td>\n",
       "      <td>setwd(\"/Users/mlr/OneDrive - Victoria Universi...</td>\n",
       "      <td>thod</td>\n",
       "      <td>method</td>\n",
       "      <td>f_key_argument</td>\n",
       "      <td>prefix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://api.github.com/repos/jayhesselberth/gg...</td>\n",
       "      <td>context(\"ggsave\")\\n\\ntest_that(\"ggsave creates...</td>\n",
       "      <td>cale</td>\n",
       "      <td>scale</td>\n",
       "      <td>f_key_argument</td>\n",
       "      <td>prefix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://api.github.com/repos/gtesei/fast-furio...</td>\n",
       "      <td>require(xgboost)\\nrequire(methods)\\nlibrary(da...</td>\n",
       "      <td>op</td>\n",
       "      <td>drop</td>\n",
       "      <td>f_key_argument</td>\n",
       "      <td>prefix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://api.github.com/repos/HadiEO/tropical_r...</td>\n",
       "      <td>require(ggplot2)\\nrequire(tidyverse)\\nrequire(...</td>\n",
       "      <td>ir</td>\n",
       "      <td>nir</td>\n",
       "      <td>f_key_argument</td>\n",
       "      <td>prefix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://api.github.com/repos/CenterForStatisti...   \n",
       "1  https://api.github.com/repos/VUW-FAIR/tic-pers...   \n",
       "2  https://api.github.com/repos/jayhesselberth/gg...   \n",
       "3  https://api.github.com/repos/gtesei/fast-furio...   \n",
       "4  https://api.github.com/repos/HadiEO/tropical_r...   \n",
       "\n",
       "                                       before_cursor after_cursor  \\\n",
       "0  ########################\\n#                   ...       otlist   \n",
       "1  setwd(\"/Users/mlr/OneDrive - Victoria Universi...         thod   \n",
       "2  context(\"ggsave\")\\n\\ntest_that(\"ggsave creates...         cale   \n",
       "3  require(xgboost)\\nrequire(methods)\\nlibrary(da...           op   \n",
       "4  require(ggplot2)\\nrequire(tidyverse)\\nrequire(...           ir   \n",
       "\n",
       "  after_cursor_token           group  prefix  \n",
       "0           plotlist  f_key_argument  prefix  \n",
       "1             method  f_key_argument  prefix  \n",
       "2              scale  f_key_argument  prefix  \n",
       "3               drop  f_key_argument  prefix  \n",
       "4                nir  f_key_argument  prefix  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if model_type == Model.BiGPT:\n",
    "    df = create_df(DATA_DIR+'extracted_events_with_right_context.json')\n",
    "elif model_type == Model.GPT:\n",
    "    df = create_df(DATA_DIR+'extracted_events.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для измерения зависимости от итерации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_to_keep = 100\n",
    "\n",
    "params = {\n",
    "    'preprocessor': preprocesser,\n",
    "    'tokenizer': tokenizer,\n",
    "    'model': model,\n",
    "    'next_token_chooser': NextTokenChooser(do_sample=False),\n",
    "    'max_tokens_amount': 5,\n",
    "    'num_beams': 5,\n",
    "    'max_num_sequence_return': 20,\n",
    "    'input_lines_to_keep': lines_to_keep,\n",
    "}\n",
    "\n",
    "if model_type == Model.BiGPT:\n",
    "    autocompletion_model = BiAutocompletionModel(\n",
    "        score_postprocesser=BiTokenScoresPostprocessor(temperature=1.5, penalty_theta=0.5),\n",
    "        **params\n",
    "    )\n",
    "elif model_type == Model.GPT:\n",
    "    autocompletion_model = AutocompletionModel(\n",
    "        score_postprocesser=TokenScoresPostprocessor(temperature=1.5, penalty_theta=0.5),\n",
    "        **params\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9f55d7355b4a80a9bd265628ff502b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "all_real_outputs = dict()\n",
    "all_model_outputs = dict()\n",
    " \n",
    "model_outputs = []\n",
    "real_outputs = []\n",
    "bad_indexes = []\n",
    "for i, elem in tqdm(df.iterrows()):\n",
    "    if model_type == Model.BiGPT:\n",
    "        test_sample = (elem['before_cursor'], elem['right_context'])\n",
    "    else:\n",
    "        test_sample = elem['before_cursor']\n",
    "    try:\n",
    "        one_model_outputs = autocompletion_model.autocomplete_input(\n",
    "            test_sample,\n",
    "            drop_last_word='always' if elem['prefix'] == 'prefix' else 'never',\n",
    "        )\n",
    "        one_real_output = elem['after_cursor_token']\n",
    "        model_outputs.append(one_model_outputs)\n",
    "        real_outputs.append(one_real_output)\n",
    "    except Exception:\n",
    "#         raise\n",
    "        bad_indexes.append(i)\n",
    "#     if i > 10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bad_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all brackets from left context\n",
    "real_o = real_outputs\n",
    "model_o = model_outputs\n",
    "relevances = [\n",
    "    [int(x == one_r_o) for x in one_model_o]\n",
    "    for one_r_o, one_model_o in zip(real_o, model_o)\n",
    "]\n",
    "key_metrics = [\n",
    "    [relevant_in_k(one_r, k=k) for k in range(1, 6)] + [reciprocal_rank(one_r)]\n",
    "    if one_r else [0] * 6\n",
    "    for one_r in relevances\n",
    "]\n",
    "key_metrics = np.array(key_metrics).mean(axis=0)\n",
    "key_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}